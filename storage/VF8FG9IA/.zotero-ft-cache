
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2212.00992

Help | Advanced Search
Search
Computer Science > Machine Learning
(cs)
[Submitted on 2 Dec 2022]
Title: Stable Learning via Sparse Variable Independence
Authors: Han Yu , Peng Cui , Yue He , Zheyan Shen , Yong Lin , Renzhe Xu , Xingxuan Zhang
Download a PDF of the paper titled Stable Learning via Sparse Variable Independence, by Han Yu and 6 other authors
Download PDF

    Abstract: The problem of covariate-shift generalization has attracted intensive research attention. Previous stable learning algorithms employ sample reweighting schemes to decorrelate the covariates when there is no explicit domain information about training data. However, with finite samples, it is difficult to achieve the desirable weights that ensure perfect independence to get rid of the unstable variables. Besides, decorrelating within stable variables may bring about high variance of learned models because of the over-reduced effective sample size. A tremendous sample size is required for these algorithms to work. In this paper, with theoretical justification, we propose SVI (Sparse Variable Independence) for the covariate-shift generalization problem. We introduce sparsity constraint to compensate for the imperfectness of sample reweighting under the finite-sample setting in previous methods. Furthermore, we organically combine independence-based sample reweighting and sparsity-based variable selection in an iterative way to avoid decorrelating within stable variables, increasing the effective sample size to alleviate variance inflation. Experiments on both synthetic and real-world datasets demonstrate the improvement of covariate-shift generalization performance brought by SVI. 

Comments: 	Accepted by AAAI 2023
Subjects: 	Machine Learning (cs.LG) ; Machine Learning (stat.ML)
Cite as: 	arXiv:2212.00992 [cs.LG]
  	(or arXiv:2212.00992v1 [cs.LG] for this version)
  	https://doi.org/10.48550/arXiv.2212.00992
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Han Yu [ view email ]
[v1] Fri, 2 Dec 2022 05:59:30 UTC (320 KB)
Full-text links:
Access Paper:

    Download a PDF of the paper titled Stable Learning via Sparse Variable Independence, by Han Yu and 6 other authors
    Download PDF
    PostScript
    Other Formats 

( view license )
Current browse context:
cs.LG
< prev   |   next >
new | recent | 2212
Change to browse by:
cs
stat
stat.ML
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

